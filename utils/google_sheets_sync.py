import os
import pandas as pd
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import logging
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Google Sheets API è¨­å®š
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
SERVICE_ACCOUNT_FILE = 'google_credentials.json'  # ä½ çš„æœå‹™å¸³è™Ÿ JSON æª”æ¡ˆ
SPREADSHEET_ID = os.getenv('GOOGLE_SHEET_ID')  # åœ¨ .env ä¸­è¨­å®š

def get_sheets_service():
    """å»ºç«‹ Google Sheets API æœå‹™"""
    try:
        creds = Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES
        )
        service = build('sheets', 'v4', credentials=creds)
        return service
    except Exception as e:
        logger.error(f"âŒ ç„¡æ³•é€£æ¥ Google Sheets API: {e}")
        return None

def create_or_update_sheet(service, spreadsheet_id, sheet_name, data):
    """å‰µå»ºæˆ–æ›´æ–°å·¥ä½œè¡¨"""
    try:
        # æª¢æŸ¥å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        sheets = spreadsheet.get('sheets', [])
        sheet_exists = any(sheet['properties']['title'] == sheet_name for sheet in sheets)

        if not sheet_exists:
            # å‰µå»ºæ–°å·¥ä½œè¡¨
            request_body = {
                'requests': [{
                    'addSheet': {
                        'properties': {
                            'title': sheet_name
                        }
                    }
                }]
            }
            service.spreadsheets().batchUpdate(
                spreadsheetId=spreadsheet_id,
                body=request_body
            ).execute()
            logger.info(f"âœ… å·²å‰µå»ºå·¥ä½œè¡¨: {sheet_name}")

        # æº–å‚™æ•¸æ“šï¼ˆè™•ç† NaN å’Œç‰¹æ®Šé¡å‹ï¼‰
        # å°‡ DataFrame è½‰æ›ç‚ºå­—ç¬¦ä¸²ï¼Œé¿å… JSON åºåˆ—åŒ–å•é¡Œ
        data_clean = data.copy()

        # å°‡æ‰€æœ‰æ¬„ä½è½‰æ›ç‚ºå­—ç¬¦ä¸²ï¼Œè™•ç† NaN
        for col in data_clean.columns:
            data_clean[col] = data_clean[col].apply(
                lambda x: '' if pd.isna(x) else str(x)
            )

        values = [data_clean.columns.tolist()] + data_clean.values.tolist()

        # æ›´æ–°æ•¸æ“š
        range_name = f"{sheet_name}!A1"
        body = {'values': values}

        result = service.spreadsheets().values().update(
            spreadsheetId=spreadsheet_id,
            range=range_name,
            valueInputOption='RAW',
            body=body
        ).execute()

        logger.info(f"âœ… å·²æ›´æ–° {result.get('updatedCells')} å€‹å„²å­˜æ ¼")
        return True

    except HttpError as error:
        logger.error(f"âŒ Google Sheets API éŒ¯èª¤: {error}")
        return False

def append_to_sheet(service, spreadsheet_id, sheet_name, data):
    """è¿½åŠ æ•¸æ“šåˆ°å·¥ä½œè¡¨ï¼ˆä¸è¦†è“‹èˆŠæ•¸æ“šï¼‰"""
    try:
        values = data.values.tolist()
        range_name = f"{sheet_name}!A:Z"

        body = {'values': values}

        result = service.spreadsheets().values().append(
            spreadsheetId=spreadsheet_id,
            range=range_name,
            valueInputOption='RAW',
            insertDataOption='INSERT_ROWS',
            body=body
        ).execute()

        logger.info(f"âœ… å·²è¿½åŠ  {result.get('updates').get('updatedRows')} è¡Œæ•¸æ“š")
        return True

    except HttpError as error:
        logger.error(f"âŒ Google Sheets API éŒ¯èª¤: {error}")
        return False

def sync_bets_to_sheets():
    """åŒæ­¥ä¸‹æ³¨è¨˜éŒ„åˆ° Google Sheets"""
    try:
        # è®€å– CSV æª”æ¡ˆ
        csv_file = 'data/polymarket_bets.csv'
        if not os.path.exists(csv_file):
            logger.warning("âš ï¸ æ‰¾ä¸åˆ° polymarket_bets.csv")
            return

        # å˜—è©¦è®€å– CSVï¼Œè™•ç†æ ¼å¼éŒ¯èª¤
        try:
            df = pd.read_csv(csv_file)
        except pd.errors.ParserError as e:
            logger.warning(f"âš ï¸ CSV æ ¼å¼éŒ¯èª¤ï¼Œå˜—è©¦ä¿®å¾©: {e}")
            # ä½¿ç”¨ error_bad_lines=False è·³ééŒ¯èª¤è¡Œï¼ˆèˆŠç‰ˆ pandasï¼‰
            # æˆ–ä½¿ç”¨ on_bad_lines='skip'ï¼ˆæ–°ç‰ˆ pandasï¼‰
            try:
                df = pd.read_csv(csv_file, on_bad_lines='skip')
            except TypeError:
                # å¦‚æœæ˜¯èˆŠç‰ˆ pandas
                df = pd.read_csv(csv_file, error_bad_lines=False, warn_bad_lines=True)

            logger.warning(f"âš ï¸ å·²è·³é {len(df)} è¡ŒéŒ¯èª¤æ•¸æ“š")

        # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“š
        if df.empty:
            logger.warning("âš ï¸ CSV æª”æ¡ˆç‚ºç©º")
            return

        # é€£æ¥ Google Sheets
        service = get_sheets_service()
        if not service:
            return

        if not SPREADSHEET_ID:
            logger.warning("âš ï¸  æœªè¨­å®š GOOGLE_SHEET_IDï¼Œè·³é Google Sheets åŒæ­¥")
            logger.info("ğŸ’¡ å¦‚éœ€å•Ÿç”¨ Google Sheets åŒæ­¥ï¼Œè«‹åƒè€ƒ setup_google_sheets.md")
            return

        # åŒæ­¥åˆ° "Bets" å·¥ä½œè¡¨
        success = create_or_update_sheet(service, SPREADSHEET_ID, 'Bets', df)

        if success:
            logger.info("âœ… æ•¸æ“šå·²æˆåŠŸåŒæ­¥åˆ° Google Sheets")
            logger.info(f"ğŸ“Š æŸ¥çœ‹: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}")
        else:
            logger.error("âŒ åŒæ­¥å¤±æ•—")

    except Exception as e:
        logger.error(f"âŒ åŒæ­¥éŒ¯èª¤: {e}", exc_info=True)

def sync_daily_summary():
    """åŒæ­¥æ¯æ—¥æ‘˜è¦åˆ° Google Sheets"""
    try:
        csv_file = 'data/polymarket_bets.csv'
        if not os.path.exists(csv_file):
            return

        # å˜—è©¦è®€å– CSV
        try:
            df = pd.read_csv(csv_file)
        except pd.errors.ParserError:
            try:
                df = pd.read_csv(csv_file, on_bad_lines='skip')
            except TypeError:
                df = pd.read_csv(csv_file, error_bad_lines=False, warn_bad_lines=True)

        if df.empty:
            return

        # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        required_columns = ['Date', 'Pick']
        if not all(col in df.columns for col in required_columns):
            logger.warning(f"âš ï¸ CSV ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œç›®å‰æ¬„ä½: {df.columns.tolist()}")
            return

        # è¨ˆç®—æ¯æ—¥çµ±è¨ˆï¼ˆæ ¹æ“šå¯¦éš›å­˜åœ¨çš„æ¬„ä½ï¼‰
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date

        agg_dict = {'Pick': 'count'}

        if 'Kelly_Stake' in df.columns:
            agg_dict['Kelly_Stake'] = 'sum'
        elif 'Stake' in df.columns:
            agg_dict['Stake'] = 'sum'

        if 'Expected_Profit' in df.columns:
            agg_dict['Expected_Profit'] = 'sum'

        if 'Actual_Profit' in df.columns:
            agg_dict['Actual_Profit'] = lambda x: pd.to_numeric(x, errors='coerce').sum()

        daily_summary = df.groupby('Date').agg(agg_dict).reset_index()

        # åŒæ­¥åˆ° "Daily Summary" å·¥ä½œè¡¨
        service = get_sheets_service()
        if service and SPREADSHEET_ID:
            create_or_update_sheet(service, SPREADSHEET_ID, 'Daily Summary', daily_summary)
            logger.info("âœ… æ¯æ—¥æ‘˜è¦å·²åŒæ­¥")

    except Exception as e:
        logger.error(f"âŒ åŒæ­¥æ¯æ—¥æ‘˜è¦éŒ¯èª¤: {e}", exc_info=True)

def format_sheet(service, spreadsheet_id, sheet_name):
    """æ ¼å¼åŒ–å·¥ä½œè¡¨ï¼ˆæ¨™é¡ŒåŠ ç²—ã€å‡çµé¦–è¡Œç­‰ï¼‰"""
    try:
        # ç²å–å·¥ä½œè¡¨ ID
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        sheets = spreadsheet.get('sheets', [])
        sheet_id = None

        for sheet in sheets:
            if sheet['properties']['title'] == sheet_name:
                sheet_id = sheet['properties']['sheetId']
                break

        if sheet_id is None:
            return

        requests = [
            # å‡çµé¦–è¡Œ
            {
                'updateSheetProperties': {
                    'properties': {
                        'sheetId': sheet_id,
                        'gridProperties': {
                            'frozenRowCount': 1
                        }
                    },
                    'fields': 'gridProperties.frozenRowCount'
                }
            },
            # æ¨™é¡Œè¡ŒåŠ ç²—
            {
                'repeatCell': {
                    'range': {
                        'sheetId': sheet_id,
                        'startRowIndex': 0,
                        'endRowIndex': 1
                    },
                    'cell': {
                        'userEnteredFormat': {
                            'textFormat': {
                                'bold': True
                            }
                        }
                    },
                    'fields': 'userEnteredFormat.textFormat.bold'
                }
            }
        ]

        body = {'requests': requests}
        service.spreadsheets().batchUpdate(
            spreadsheetId=spreadsheet_id,
            body=body
        ).execute()

        logger.info(f"âœ… å·²æ ¼å¼åŒ–å·¥ä½œè¡¨: {sheet_name}")

    except Exception as e:
        logger.error(f"âŒ æ ¼å¼åŒ–éŒ¯èª¤: {e}")

if __name__ == "__main__":
    logger.info("ğŸš€ é–‹å§‹åŒæ­¥æ•¸æ“šåˆ° Google Sheets...")
    sync_bets_to_sheets()
    sync_daily_summary()

    # æ ¼å¼åŒ–å·¥ä½œè¡¨
    service = get_sheets_service()
    if service and SPREADSHEET_ID:
        format_sheet(service, SPREADSHEET_ID, 'Bets')
        format_sheet(service, SPREADSHEET_ID, 'Daily Summary')

    logger.info("âœ… åŒæ­¥å®Œæˆï¼")
